\section{Discussion}
\label{sec:discussion}

We probed the linguistic information induced by an LSTM language model
trained on unsegmented text at the character level. We found that the
model stores implicit knowledge about phonotactic constraints, word
units, major morphosyntactic classes, non-adjacent syntactic agreement
and subcategorization phenomena and even some degree of semantic
knowledge. While a more standard model pre-initialized with a word
vocabulary and reading tokenized input was in general superior on the
higher-level tasks, the performance of our agnostic model did not
generally lag much behind, suggesting that the word bias is helpful
but not fundamental. The performance of character-level RNN was
considerably less consistent than that of the equivalent LSTM, suggesting that
the ability of the latter to track information across longer time
steps is important to extract linguistic generalizations from the raw
input. Importantly, n-gram baselines only relying on adjacent string
statistics fail almost all tests, showing that the neural models
are tapping into somewhat deeper linguistic templates.

Our results are very preliminary in many ways. The tests we used are
generally simple \cite[we did not attempt, for example, to model
long-distance subject-verb agreement, a task that is challenging even
for word-based models:][]{Linzen:etal:2016}, and they only probe a
small subset of linguistic rules. Still, they do suggest that a large
corpus, combined with the very weak priors encoded in an LSTM, might
suffice to discover generalizations that appear to be of a genuine
linguistic nature.

One aspect that we find particularly intriguing is that, unlike the
standard word-based models, our CNLMs do not have a morpheme- or
word-based lexicon. Any information the network might acquire about
units larger than characters must be stored in its recurrent
weights. Given that nearly all contemporary linguistics recognizes a
central role to the lexicon \cite[see, e.g.,][for different
perspectives]{Sag:etal:2003,Goldberg:2005,Radford:2006,Bresnan:etal:2016,Jezek:2016},
in future work we would like to explore how lexical knowledge is
implicitly encoded in the distributed memory of our CNLMs.

One of our original motivations for not assuming word primitives is that a rigid word notion is problematic both cross-linguistically (cf.~polysynthetic and agglutinative languages) and when analyzing a single language (cf.~the common  view  that the lexicon hosts units at different levels of the linguistic hierarchy, from  morphemes to large syntactic constructions). Our brief analysis of the CNLM over- and undersegmentations suggested that it is indeed capable to flexibly store information about units at different levels. However, this topic  remained largely unexplored, and we plan to systematically tackle it in future work.

